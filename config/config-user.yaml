openchat_3.5.Q8_0.gguf$:
  loader: llama.cpp
  cpu: false
  threads: 32
  threads_batch: 32
  n_batch: 2048
  no_mmap: false
  mlock: false
  no_mul_mat_q: false
  n_gpu_layers: 256
  tensor_split: ''
  n_ctx: 18432
  compress_pos_emb: 1
  alpha_value: 1
  rope_freq_base: 0
  numa: false
  no_offload_kqv: false
  row_split: false
  tensorcores: false
  flash-attn: false
  streaming_llm: false
  attention_sink_size: 5
